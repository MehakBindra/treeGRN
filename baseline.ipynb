{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d83909a-d458-48c3-b00a-dfe4478c709d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2bcd73f8-6db7-42ba-a54b-1655f3d78245",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_file = f\"data/5_mr_50_cond/simulated_noNoise.txt\"\n",
    "grn_file = f\"data/5_mr_50_cond/bipartite_GRN.csv\"\n",
    "\n",
    "data = pd.read_csv(data_file, sep = \"\\t\", header = 0)\n",
    "grn_df = pd.read_csv(grn_file, sep = \",\", header = None)\n",
    "grn_true = pd.Series(zip(*map(grn_df.get, grn_df)), name='edges').to_frame()\n",
    "grn_true['class'] = 1\n",
    "\n",
    "# compute pairwise person correlations between genes and TFs\n",
    "corr_mat = data.corr(method=\"pearson\").abs().iloc[100:,:100]\n",
    "corr_dict = corr_mat.unstack().to_dict()\n",
    "\n",
    "grn_pred = pd.concat([pd.Series(corr_dict.keys(), name='edges'),  pd.Series(corr_dict.values(), name='corr')], axis=1)\n",
    "\n",
    "grn_eval = pd.merge(grn_pred, grn_true, on='edges', how=\"left\")\n",
    "grn_eval['class'] = grn_eval['class'].fillna(int(0))\n",
    "\n",
    "grn_eval.to_csv(r\"results/5_mr_50_cond/top_corr.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[24], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Antonio: splitting the cells because I am getting an error in this cell\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mmetrics\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mroc_auc_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgrn_eval\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mclass\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrn_eval\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcorr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m100\u001B[39m):\n\u001B[1;32m      5\u001B[0m     grn_eval_gene \u001B[38;5;241m=\u001B[39m grn_eval\u001B[38;5;241m.\u001B[39miloc[i::\u001B[38;5;241m100\u001B[39m,:]\n",
      "File \u001B[0;32m/opt/anaconda3/envs/treeGRN/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:214\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    208\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    209\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m    210\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m    211\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m    212\u001B[0m         )\n\u001B[1;32m    213\u001B[0m     ):\n\u001B[0;32m--> 214\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[1;32m    217\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[1;32m    219\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[1;32m    220\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[1;32m    221\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    222\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    223\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[1;32m    224\u001B[0m     )\n",
      "File \u001B[0;32m/opt/anaconda3/envs/treeGRN/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:627\u001B[0m, in \u001B[0;36mroc_auc_score\u001B[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001B[0m\n\u001B[1;32m    625\u001B[0m     labels \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39munique(y_true)\n\u001B[1;32m    626\u001B[0m     y_true \u001B[38;5;241m=\u001B[39m label_binarize(y_true, classes\u001B[38;5;241m=\u001B[39mlabels)[:, \u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m--> 627\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_average_binary_score\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    628\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpartial\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_binary_roc_auc_score\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_fpr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_fpr\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    629\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    630\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    631\u001B[0m \u001B[43m        \u001B[49m\u001B[43maverage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    632\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    633\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    634\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:  \u001B[38;5;66;03m# multilabel-indicator\u001B[39;00m\n\u001B[1;32m    635\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _average_binary_score(\n\u001B[1;32m    636\u001B[0m         partial(_binary_roc_auc_score, max_fpr\u001B[38;5;241m=\u001B[39mmax_fpr),\n\u001B[1;32m    637\u001B[0m         y_true,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    640\u001B[0m         sample_weight\u001B[38;5;241m=\u001B[39msample_weight,\n\u001B[1;32m    641\u001B[0m     )\n",
      "File \u001B[0;32m/opt/anaconda3/envs/treeGRN/lib/python3.10/site-packages/sklearn/metrics/_base.py:75\u001B[0m, in \u001B[0;36m_average_binary_score\u001B[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001B[0m\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m format is not supported\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(y_type))\n\u001B[1;32m     74\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m---> 75\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mbinary_metric\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_score\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     77\u001B[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001B[1;32m     78\u001B[0m y_true \u001B[38;5;241m=\u001B[39m check_array(y_true)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/treeGRN/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:382\u001B[0m, in \u001B[0;36m_binary_roc_auc_score\u001B[0;34m(y_true, y_score, sample_weight, max_fpr)\u001B[0m\n\u001B[1;32m    380\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Binary roc auc score.\"\"\"\u001B[39;00m\n\u001B[1;32m    381\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(np\u001B[38;5;241m.\u001B[39munique(y_true)) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[0;32m--> 382\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    383\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOnly one class present in y_true. ROC AUC score \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    384\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis not defined in that case.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    385\u001B[0m     )\n\u001B[1;32m    387\u001B[0m fpr, tpr, _ \u001B[38;5;241m=\u001B[39m roc_curve(y_true, y_score, sample_weight\u001B[38;5;241m=\u001B[39msample_weight)\n\u001B[1;32m    388\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m max_fpr \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m max_fpr \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
      "\u001B[0;31mValueError\u001B[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "# Antonio: splitting the cells because I am getting an error in this cell\n",
    "print(metrics.roc_auc_score(grn_eval['class'], grn_eval['corr']))\n",
    "\n",
    "for i in range(100):\n",
    "    grn_eval_gene = grn_eval.iloc[i::100,:]\n",
    "    print(metrics.roc_auc_score(grn_eval_gene['class'], grn_eval_gene['corr']))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8efc7f-6a50-4a01-b412-71dac834054d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# data_file = f\"data/40_mr_50_cond/simulated_noNoise.txt\"\n",
    "# grn_file = f\"data/40_mr_50_cond/bipartite_GRN.csv\"\n",
    "#\n",
    "# data = pd.read_csv(data_file, sep = \"\\t\", header = None)\n",
    "# grn_df = pd.read_csv(grn_file, sep = \",\", header = None)\n",
    "# grn_true = pd.Series(zip(*map(grn_df.get, grn_df)), name='edges').to_frame()\n",
    "# grn_true['class'] = 1\n",
    "#\n",
    "# corr_mat = data.corr(method=\"pearson\").abs().iloc[100:,:100]\n",
    "# corr_dict = corr_mat.unstack().to_dict()\n",
    "#\n",
    "# grn_pred = pd.concat([pd.Series(corr_dict.keys(), name='edges'),  pd.Series(corr_dict.values(), name='corr')], axis=1)\n",
    "#\n",
    "# grn_eval = pd.merge(grn_pred, grn_true, on='edges', how=\"left\")\n",
    "# grn_eval['class'] = grn_eval['class'].fillna(int(0))\n",
    "#\n",
    "# grn_eval.to_csv(r\"results/40_mr_50_cond/top_corr.csv\")\n",
    "#\n",
    "# print(metrics.roc_auc_score(grn_eval['class'], grn_eval['corr']))\n",
    "#\n",
    "# for i in range(100):\n",
    "#     grn_eval_gene = grn_eval.iloc[i::100,:]\n",
    "#     print(metrics.roc_auc_score(grn_eval_gene['class'], grn_eval_gene['corr']))\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5e597f-f6ff-4aaf-8d08-f5863f936e32",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# data_file = f\"data/100_mr_50_cond/simulated_noNoise.txt\"\n",
    "# grn_file = f\"data/100_mr_50_cond/bipartite_GRN.csv\"\n",
    "#\n",
    "# data = pd.read_csv(data_file, sep = \"\\t\", header = None)\n",
    "# grn_df = pd.read_csv(grn_file, sep = \",\", header = None)\n",
    "# grn_true = pd.Series(zip(*map(grn_df.get, grn_df)), name='edges').to_frame()\n",
    "# grn_true['class'] = 1\n",
    "#\n",
    "# corr_mat = data.corr(method=\"pearson\").abs().iloc[100:,:100]\n",
    "# corr_dict = corr_mat.unstack().to_dict()\n",
    "#\n",
    "# grn_pred = pd.concat([pd.Series(corr_dict.keys(), name='edges'),  pd.Series(corr_dict.values(), name='corr')], axis=1)\n",
    "#\n",
    "# grn_eval = pd.merge(grn_pred, grn_true, on='edges', how=\"left\")\n",
    "# grn_eval['class'] = grn_eval['class'].fillna(int(0))\n",
    "#\n",
    "# grn_eval.to_csv(r\"results/100_mr_50_cond/top_corr.csv\")\n",
    "#\n",
    "# print(metrics.roc_auc_score(grn_eval['class'], grn_eval['corr']))\n",
    "#\n",
    "# for i in range(100):\n",
    "#     grn_eval_gene = grn_eval.iloc[i::100,:]\n",
    "#     print(metrics.roc_auc_score(grn_eval_gene['class'], grn_eval_gene['corr']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1191ce97-5d94-416c-be1d-978ad1a6a9ea",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}