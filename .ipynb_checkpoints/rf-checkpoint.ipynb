{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7d358ab-4376-49f0-aa5c-3713f1099365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc\n",
    "from statistics import mean\n",
    "import shap\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import ranksums\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f39b91b-e73a-4296-bd66-e269a864c30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MR = [5, 40, 100]\n",
    "N_genes = 100  # total no. of genes\n",
    "N_TFs = N_genes\n",
    "\n",
    "n_estimators=[500, 1000, 2000]  # number of trees in the forest\n",
    "criterion='squared_error'  # variance reduction equivalent\n",
    "max_features = ['sqrt', N_TFs ] # max no. of features to use in each split \n",
    "random_state = 42  # for reproducibility\n",
    "bootstrap = [True, False ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "448a836b-bb68-4daf-8f48-d7d3c1019f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf_results = pd.DataFrame(columns=['MR', 'FI', 'N_EST', 'MAX_FEATURES','BOOTSTRAPPING', 'AUPRC', 'AUROC', 'MEAN_AUROC', 'p-value', 'BOOSTING'])\n",
    "#rf_results.to_csv(\"results/grn_rf_results.csv\", index=False)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a5cbf81-bec1-4165-acd0-19ae50e1e381",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mr in MR:\n",
    "    for n_est in n_estimators:\n",
    "        for m_f in max_features:\n",
    "            for b_s in bootstrap:\n",
    "                \n",
    "                rf_results = pd.read_csv(\"results/grn_rf_results.csv\", header=0)\n",
    "                \n",
    "                data_file = (\"data/{}_mr_50_cond/simulated_noNoise.txt\").format(mr)\n",
    "                grn_file = (\"data/{}_mr_50_cond/bipartite_GRN.csv\").format(mr)\n",
    "\n",
    "                data = pd.read_csv(data_file, sep=\"\\t\", header=0)\n",
    "                grn_df = pd.read_csv(grn_file, sep = \",\", header = None, names=['TF_ID', 'G_ID'])\n",
    "                grn_df['class'] = 1\n",
    "\n",
    "                # Normalize Expression data to unit-variance\n",
    "                data_n = StandardScaler(with_mean=False).fit_transform(data.to_numpy())\n",
    "\n",
    "                # Initialize matrices\n",
    "                W = np.zeros(shape=(N_genes,N_TFs))\n",
    "                W_shap = np.zeros(shape=(N_genes,N_TFs))\n",
    "                Fscores = np.zeros(shape=(N_genes,))\n",
    "\n",
    "                for j in np.arange(0,N_genes):\n",
    "                    # read TF and gene expression data X and Gj\n",
    "                    X, Gj= data_n[:,:N_TFs], data_n[:,N_genes+j]\n",
    "\n",
    "                    # fit an RF model to predict gene expression from TF\n",
    "                    M_rf = RandomForestRegressor(criterion=criterion, n_estimators=n_est, max_features=m_f, bootstrap=b_s, random_state=random_state).fit(X,Gj)\n",
    "\n",
    "                    # train score\n",
    "                    Fscores[j] = M_rf.score(X,Gj)\n",
    "\n",
    "                    # Get the weights for all edges connecting TFs to gene j\n",
    "                    W[j,:] = M_rf.feature_importances_\n",
    "\n",
    "                    # look at feature importance based on SHAP values\n",
    "                    explainer = shap.TreeExplainer(M_rf)\n",
    "                    shap_values = explainer(X)\n",
    "                    W_shap[j,:] = np.mean(np.abs(shap_values.values), axis=0)\n",
    "                    \n",
    "                W_df = pd.DataFrame(np.abs(W))\n",
    "\n",
    "                grn_pred = pd.melt(W_df.reset_index(), id_vars = 'index', var_name='TF_ID', value_name='W_pred').rename(columns={'index': 'G_ID'})\n",
    "\n",
    "                grn_pred['G_ID'] = grn_pred['G_ID'].astype(np.int64) + 100\n",
    "                grn_pred['TF_ID'] = grn_pred['TF_ID'].astype(np.int64)\n",
    "\n",
    "                grn_eval = pd.merge(grn_pred,grn_df, on=['G_ID', 'TF_ID'], how='left')\n",
    "                grn_eval['class'] = grn_eval['class'].fillna(int(0))\n",
    "\n",
    "                grn_eval.to_csv(\"results/{}_mr_50_cond/grn_eval_rf_vr_{}_{}_{}.csv\".format(mr,n_est,m_f,b_s))\n",
    "\n",
    "                precision, recall, thresholds_prc = precision_recall_curve(grn_eval['class'], grn_eval['W_pred'])\n",
    "                fpr, tpr, thresholds_roc = roc_curve(grn_eval['class'], grn_eval['W_pred'])\n",
    "                auprc = auc(recall, precision)\n",
    "                auroc = auc(fpr,tpr)\n",
    "\n",
    "                roc_gene = [] \n",
    "                for i in range(100):\n",
    "                    grn_eval_gene = grn_eval.iloc[i::N_TFs,:]\n",
    "                    roc_gene.append(metrics.roc_auc_score(grn_eval_gene['class'], grn_eval_gene['W_pred']))\n",
    "\n",
    "                mean_auroc = mean(roc_gene)\n",
    "\n",
    "                ranksums_pvalue = ranksums(grn_eval[grn_eval['class']==1]['W_pred'], grn_eval[grn_eval['class']==0]['W_pred'], alternative='greater')\n",
    "\n",
    "                prc = pd.DataFrame({'precision': precision, 'recall': recall}, columns=['precision', 'recall'])\n",
    "                roc = pd.DataFrame({'fpr': fpr, 'tpr': tpr}, columns=['fpr', 'tpr'])\n",
    "                prc.to_csv(\"results/{}_mr_50_cond/grn_prc_rf_vr_{}_{}_{}.csv\".format(mr,n_est,m_f,b_s))\n",
    "                roc.to_csv(\"results/{}_mr_50_cond/grn_roc_rf_vr_{}_{}_{}.csv\".format(mr,n_est,m_f,b_s))\n",
    "                \n",
    "                temp1 = pd.DataFrame([[mr, \"VR\", n_est, m_f, b_s, auprc, auroc, mean_auroc, ranksums_pvalue[1], \"No\"]], \\\n",
    "                        columns=['MR', 'FI', 'N_EST', 'MAX_FEATURES','BOOTSTRAPPING', 'AUPRC', 'AUROC', 'MEAN_AUROC', 'p-value', 'BOOSTING'])\n",
    "         \n",
    "                W_shap_df = pd.DataFrame(np.abs(W_shap))\n",
    "\n",
    "                grn_pred_shap = pd.melt(W_shap_df.reset_index(), id_vars = 'index', var_name='TF_ID', value_name='W_pred').rename(columns={'index': 'G_ID'})\n",
    "\n",
    "                grn_pred_shap['G_ID'] = grn_pred_shap['G_ID'].astype(np.int64) + 100\n",
    "                grn_pred_shap['TF_ID'] = grn_pred_shap['TF_ID'].astype(np.int64)\n",
    "\n",
    "                grn_eval_shap = pd.merge(grn_pred_shap,grn_df, on=['G_ID', 'TF_ID'], how='left')\n",
    "                grn_eval_shap['class'] = grn_eval_shap['class'].fillna(int(0)) == 1.0\n",
    "\n",
    "                grn_eval_shap.to_csv(\"results/{}_mr_50_cond/grn_eval_rf_shap_{}_{}_{}.csv\".format(mr,n_est,m_f,b_s))\n",
    "\n",
    "                precision, recall, thresholds_prc = precision_recall_curve(grn_eval_shap['class'], grn_eval_shap['W_pred'])\n",
    "                fpr, tpr, thresholds_roc = roc_curve(grn_eval_shap['class'], grn_eval_shap['W_pred'])\n",
    "                auprc = auc(recall, precision)\n",
    "                auroc = auc(fpr,tpr)\n",
    "\n",
    "                roc_gene = [] \n",
    "                for i in range(100):\n",
    "                    grn_eval_gene = grn_eval_shap.iloc[i::N_TFs,:]\n",
    "                    roc_gene.append(metrics.roc_auc_score(grn_eval_gene['class'], grn_eval_gene['W_pred']))\n",
    "\n",
    "                mean_auroc = mean(roc_gene)\n",
    "                ranksums_pvalue = ranksums(grn_eval_shap[grn_eval_shap['class']==1]['W_pred'], grn_eval_shap[grn_eval_shap['class']==0]['W_pred'], alternative='greater')\n",
    "\n",
    "                prc = pd.DataFrame({'precision': precision, 'recall': recall}, columns=['precision', 'recall'])\n",
    "                roc = pd.DataFrame({'fpr': fpr, 'tpr': tpr}, columns=['fpr', 'tpr'])\n",
    "                prc.to_csv(\"results/{}_mr_50_cond/grn_prc_rf_shap_{}_{}_{}.csv\".format(mr,n_est,m_f,b_s))\n",
    "                roc.to_csv(\"results/{}_mr_50_cond/grn_roc_rf_shap_{}_{}_{}.csv\".format(mr,n_est,m_f,b_s))\n",
    "                \n",
    "                temp2 = pd.DataFrame([[mr, \"SHAP\", n_est, m_f, b_s, auprc, auroc, mean_auroc, ranksums_pvalue[1], \"No\"]], \\\n",
    "                        columns=['MR', 'FI', 'N_EST', 'MAX_FEATURES','BOOTSTRAPPING', 'AUPRC', 'AUROC', 'MEAN_AUROC', 'p-value', 'BOOSTING'])\n",
    "                \n",
    "                df_list = [rf_results, temp1, temp2]\n",
    "                df_out = pd.concat([df for df in df_list if not df.empty])                \n",
    "                df_out.to_csv(\"results/grn_rf_results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "treeGRN",
   "language": "python",
   "name": "treegrn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
